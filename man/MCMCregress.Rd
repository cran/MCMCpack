% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/MCMCregress.R
\name{MCMCregress}
\alias{MCMCregress}
\title{Markov Chain Monte Carlo for Gaussian Linear Regression}
\usage{
MCMCregress(
  formula,
  data = NULL,
  burnin = 1000,
  mcmc = 10000,
  thin = 1,
  verbose = 0,
  seed = NA,
  beta.start = NA,
  b0 = 0,
  B0 = 0,
  c0 = 0.001,
  d0 = 0.001,
  sigma.mu = NA,
  sigma.var = NA,
  marginal.likelihood = c("none", "Laplace", "Chib95"),
  ...
)
}
\arguments{
\item{formula}{Model formula.}

\item{data}{Data frame.}

\item{burnin}{The number of burn-in iterations for the sampler.}

\item{mcmc}{The number of MCMC iterations after burnin.}

\item{thin}{The thinning interval used in the simulation.  The number of
MCMC iterations must be divisible by this value.}

\item{verbose}{A switch which determines whether or not the progress of the
sampler is printed to the screen.  If \code{verbose} is greater than 0 the
iteration number, the \eqn{\beta} vector, and the error variance are
printed to the screen every \code{verbose}th iteration.}

\item{seed}{The seed for the random number generator.  If NA, the Mersenne
Twister generator is used with default seed 12345; if an integer is passed
it is used to seed the Mersenne twister.  The user can also pass a list of
length two to use the L'Ecuyer random number generator, which is suitable
for parallel computation.  The first element of the list is the L'Ecuyer
seed, which is a vector of length six or NA (if NA a default seed of
\code{rep(12345,6)} is used).  The second element of list is a positive
substream number. See the MCMCpack specification for more details.}

\item{beta.start}{The starting values for the \eqn{\beta} vector.
This can either be a scalar or a column vector with dimension equal to the
number of betas.  The default value of of NA will use the OLS estimate of
\eqn{\beta} as the starting value.  If this is a scalar, that value
will serve as the starting value mean for all of the betas.}

\item{b0}{The prior mean of \eqn{\beta}.  This can either be a scalar
or a column vector with dimension equal to the number of betas. If this
takes a scalar value, then that value will serve as the prior mean for all
of the betas.}

\item{B0}{The prior precision of \eqn{\beta}.  This can either be a
scalar or a square matrix with dimensions equal to the number of betas.  If
this takes a scalar value, then that value times an identity matrix serves
as the prior precision of beta. Default value of 0 is equivalent to an
improper uniform prior for beta.}

\item{c0}{\eqn{c_0/2} is the shape parameter for the inverse Gamma
prior on \eqn{\sigma^2} (the variance of the disturbances). The
amount of information in the inverse Gamma prior is something like that from
\eqn{c_0} pseudo-observations.}

\item{d0}{\eqn{d_0/2} is the scale parameter for the inverse Gamma
prior on \eqn{\sigma^2} (the variance of the disturbances). In
constructing the inverse Gamma prior, \eqn{d_0} acts like the sum of
squared errors from the \eqn{c_0} pseudo-observations.}

\item{sigma.mu}{The mean of the inverse Gamma prior on
\eqn{\sigma^2}.  \eqn{sigma.mu} and
\eqn{sigma.var} allow users to choose the inverse Gamma prior by
choosing its mean and variance.}

\item{sigma.var}{The variacne of the inverse Gamma prior on
\eqn{\sigma^2}.  \eqn{sigma.mu} and
\eqn{sigma.var} allow users to choose the inverse Gamma prior by
choosing its mean and variance.}

\item{marginal.likelihood}{How should the marginal likelihood be calculated?
Options are: \code{none} in which case the marginal likelihood will not be
calculated, \code{Laplace} in which case the Laplace approximation (see Kass
and Raftery, 1995) is used, and \code{Chib95} in which case the method of
Chib (1995) is used.}

\item{...}{further arguments to be passed.}
}
\value{
An mcmc object that contains the posterior sample.  This object can
be summarized by functions provided by the coda package.
}
\description{
This function generates a sample from the posterior distribution of a linear
regression model with Gaussian errors using Gibbs sampling (with a
multivariate Gaussian prior on the beta vector, and an inverse Gamma prior
on the conditional error variance).  The user supplies data and priors, and
a sample from the posterior distribution is returned as an mcmc object,
which can be subsequently analyzed with functions provided in the coda
package.
}
\details{
\code{MCMCregress} simulates from the posterior distribution using standard
Gibbs sampling (a multivariate Normal draw for the betas, and an inverse
Gamma draw for the conditional error variance).  The simulation proper is
done in compiled C++ code to maximize efficiency.  Please consult the coda
documentation for a comprehensive list of functions that can be used to
analyze the posterior sample.

The model takes the following form:

\deqn{y_i = x_i ' \beta + \varepsilon_{i}}

Where the errors are assumed to be Gaussian:

\deqn{\varepsilon_{i} \sim \mathcal{N}(0, \sigma^2)}

We assume standard, semi-conjugate priors:

\deqn{\beta \sim \mathcal{N}(b_0,B_0^{-1})}

And:

\deqn{\sigma^{-2} \sim \mathcal{G}amma(c_0/2, d_0/2)}

Where
\eqn{\beta} and \eqn{\sigma^{-2}} are assumed \emph{a
priori} independent.  Note that only starting values for \eqn{\beta}
are allowed because simulation is done using Gibbs sampling with the
conditional error variance as the first block in the sampler.
}
\examples{

\dontrun{
line   <- list(X = c(-2,-1,0,1,2), Y = c(1,3,3,3,5))
posterior  <- MCMCregress(Y~X, b0=0, B0 = 0.1,
	      sigma.mu = 5, sigma.var = 25, data=line, verbose=1000)
plot(posterior)
raftery.diag(posterior)
summary(posterior)
}

}
\references{
Andrew D. Martin, Kevin M. Quinn, and Jong Hee Park. 2011.
``MCMCpack: Markov Chain Monte Carlo in R.'', \emph{Journal of Statistical
Software}. 42(9): 1-21.  \doi{10.18637/jss.v042.i09}.

Siddhartha Chib. 1995. ``Marginal Likelihood from the Gibbs Output.''
\emph{Journal of the American Statistical Association}. 90: 1313-1321.

Robert E. Kass and Adrian E. Raftery. 1995. ``Bayes Factors.'' \emph{Journal
of the American Statistical Association}. 90: 773-795.

Daniel Pemstein, Kevin M. Quinn, and Andrew D. Martin.  2007.  \emph{Scythe
Statistical Library 1.0.} \url{http://scythe.lsa.umich.edu}.

Martyn Plummer, Nicky Best, Kate Cowles, and Karen Vines. 2006.  ``Output
Analysis and Diagnostics for MCMC (CODA)'', \emph{R News}. 6(1): 7-11.
\url{https://CRAN.R-project.org/doc/Rnews/Rnews_2006-1.pdf}.
}
\seealso{
\code{\link[coda]{plot.mcmc}}, \code{\link[coda]{summary.mcmc}},
\code{\link[stats]{lm}}
}
\keyword{models}
